z-scheduler是参考dolphin的架构设计重新设计的任务调度框架。

> Apache DolphinScheduler是一个分布式去中心化，
易扩展的可视化DAG工作流任务调度平台。
致力于解决数据处理流程中错综复杂的依赖关系，
使调度系统在数据处理流程中开箱即用。

dolphin的侧重点是易于操作的dag关系。
z-scheduler 在此dolphin的基础上优化了任务的触发和执行的架构设计，并且扩展了功能。


项目背景：
去掉以前


比如支持任务的结果传递，自定义动态参数，任务权限校验，任务异步执行，新增客户端
组件metrics统计优化


亮点： **任务的触发和执行设计**
- 任务的触发
  - 问题点： dolphin任务触发分为两步。
    1. 基于quartz进行任务触发生成Command，放入Command表。
    2. 多个master节点获取zk分布式锁，获取一定数量的Command，默认是取一个，待command的任务放入线程池后，释放分布式锁
    
    quartz的底层触发流程是这样的：
    > 轮询扫描trigger表，获取30ms内将要执行的任务，放入待触发的表，接着获取trigger的独占锁，对trigger进行任务触发执行。
    
    这样可以看出quartz触发有几个明显的缺陷
    - 同时只有一个quartz 通过数据库悲观锁获取job，quartz集群模式下，是通过数据库独占锁来唯一获取任务，任务执行并没有实现完善的负载均衡机制。
    -  **不适合大量的短任务 & 不适合过多节点部署**；
    -  解决了高可用的问题，并没有解决任务分片的问题，存在单机处理的极限（即：不能实现水平扩展）。
    -  需要把任务信息持久化到业务数据表，和业务有耦合
       调度逻辑和执行逻辑并存于同一个项目中，在机器性能固定的情况下，业务和调度之间不可避免地会相互影响。
       
    dolphin master节点获取触发任务的缺陷和quartz类似，同时只有一个master节点获取任务，
    单点瓶颈，多master也是只解决了高可用问题，并没有提高扩展性。
    
  - 优化：
    采用消息队列+时间轮服务的方式进行定时任务触发，时间的轮的设计,部分借鉴kafka内部实现，不过kafka的时间轮是纯内存方式，不好管理和容错恢复。
    
    - trigger消息被时间轮服务监听，先写入预写日志，日志写入成功后加入时间轮，时间轮通过blockQueue poll进行时间推进,整个时间轮只有单层轮，
    因为是从已分段的日志文件里面构建。
    - 关于文件的存储读写，这块借鉴了rocketMq的CommitLog的读写，
    - 按照每天千万级的调度量预估，平均下来每小时的调度量在41万左右，每个小时按定长格式130字节存储（时间戳13），48m文件
    - 按照一个String对象约占32字节计算，消息构造成时间轮任务实例这个消息量在堆内存中差不多内存膨胀5倍，大概300m一个时间轮
    - 预写日志按时间段存储，时间目前是设置为1小时。
    - 关于已过期的桶，过期10s内的进行触发
    - 高可用设计：注册zk获取分布式锁的则为主，可以发送工作流实例消息，主从行为一致区别就是主可以发消息
    - 延时消息日志文件分为3个，message.log,scheduler.log,index.log,分别是消息的日志,按小时分片的日志，message.log消费偏移量日志
  
- 任务的执行
  因为有了dag的因素，任务的执行实际是任务链的执行。dolphin对任务链的执行分为两步：
  master解析dag每个层级的任务数，生成相应数量的线程，这些任务线程通过rpc将任务发送给work节点执行，
  同步等待任务执行结果。
  这里问题就在于任务执行的同步，如果任务耗时稍长，会造成1+n任务数的执行线程等待。
  很快耗尽线程池资源，进一步加剧任务的堆积阻塞。
  
  - 优化：
    任务执行均为异步执行，任务结果和状态变更可以通过api或者消息进行回调
    异步的难点是要确认任务投递到对方，异步投递会附加投递一个超时检测任务，到期执行
    