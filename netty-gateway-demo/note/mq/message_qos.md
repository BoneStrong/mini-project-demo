## MQTT QOS
MQTT 协议 中规定了消息服务质量（Quality of Service），它保证了在不同的网络环境下消息传递的可靠性，
QoS 的设计是 MQTT 协议里的重点。作为专为物联网场景设计的协议，MQTT 的运行场景不仅仅是 PC，
而是更广泛的窄带宽网络和低功耗设备，如果能在协议层解决传输质量的问题，将为物联网应用的开发提供极大便利。

### MQTT QoS 等级
MQTT 设计了 3 个 QoS 等级。

- QoS 0（At most once）：消息最多传递一次，如果当时客户端不可用，则会丢失该消息。
- QoS 1（At least once）：消息传递至少 1 次。
- QoS 2（ Exactly once）：消息仅传送一次。

QoS 0 是一种 "fire and forget" 的消息发送模式：Sender (可能是 Publisher 或者 Broker) 发送一条消息之后，
就不再关心它有没有发送到对方，也不设置任何重发机制。

QoS 1 包含了简单的重发机制，Sender 发送消息之后等待接收者的 ACK，如果没收到 ACK 则重新发送消息。
这种模式能保证消息至少能到达一次，但无法保证消息重复。

QoS 2 设计了重发和重复消息发现机制，保证消息到达对方并且严格只到达一次。

### Exactly once
**Exactly-Once 是指发送到消息系统的消息只能被消费端处理且仅处理一次**，即使生产端重试消息发送导致某消息重复投递，
该消息在消费端也只被消费一次。

Exactly-Once 语义是消息系统和流式计算系统中消息流转的最理想状态，但是**在业界并没有太多理想的实现**。
因为真正意义上的 Exactly-Once 依赖消息系统的服务端、消息系统的客户端和用户消费逻辑这三者状态的协调。
例如，当您的消费端完成一条消息的消费处理后出现异常宕机，而消费端重启后由于消费的位点没有同步到消息系统的服务端，
该消息有可能被重复消费。

业界对于 Exactly-Once 投递语义存在很大的争议，很多人会拿出 “FLP 不可能理论”或者其他一致性定律对此议题进行否定，
但事实上，特定场景的 Exactly-Once 语义实现并不是非常复杂，只是因为通常大家没有精确的描述问题的本质。

如果您要实现一条消息的消费结果只能在业务系统中生效一次，您需要解决的只是如何保证同一条消息的消费幂等问题。
消息队列 RocketMQ 版的 Exactly-Once 语义就是解决业务中最常见的一条消息的消费结果（消息在消费端计算处理的结果）
在数据库系统中有且仅生效一次的问题。

### kafka exactly once
但其实kafka的可靠性也只能说是相对的，在整条数据链条中，总有可以让数据出现丢失的情况，
今天就来讨论如何避免kafka数据丢失，以及实现精确一致处理的语义。

kafka无消息丢失处理在讨论如何实现kafka无消息丢失的时候，首先要先清楚大部分情况下消息丢失是在什么情况下发生的。
为什么是大部分，因为总有一些非常特殊的情况会被人忽略，而我们只需要关注普遍的情况就足够了。
接下来我们来讨论如何较为普遍的数据丢失情况。

- 生产者丢失

    前面介绍Kafka分区和副本的时候，有提到过一个producer客户端有一个acks的配置
    这个配置为0的时候，producer是发送之后不管的，这个时候就很有可能因为网络等原因造成数据丢失，所以应该尽量避免。
    
    但是将ack设置为1就没问题了吗，那也不一定，因为有可能在leader副本接收到数据，但还没同步给其他副本的时候就挂掉了，
    这时候数据也是丢失了。并且这种时候是客户端以为消息发送成功，但kafka丢失了数据。
    
    要达到最严格的无消息丢失配置，应该是**要将acks的参数设置为-1**（也就是all），
    并且将min.insync.replicas配置项调高到大于1，**同时还需要使用带有回调的producer api**，来发送数据。
    注意这里讨论的都是异步发送消息，同步发送不在讨论范围。
    
- kafka内部丢失消息
    有些时候，kafka内部因为一些不大好的配置，可能会出现一些极为隐蔽的数据丢失情况，那么我们分别讨论下大致都有哪几种情况。
    
    - replication.factor配置参数
        这个配置决定了副本的数量，默认是1。
        注意这个参数不能超过broker的数量。说这个参数其实是因为如果使用默认的1，
        或者不在创建topic的时候指定副本数量（也就是副本数为1），那么当一台机器出现磁盘损坏等情况，
        那么数据也就从kafka里面丢失了。所以replication.factor这个参数最好是配置大于1，比如说3。
        
    - unclean.leader.election.enable 参数
    
        这个参数是在主副本挂掉，然后在ISR集合中没有副本可以成为leader的时候，要不要让进度比较慢的副本成为leader的。
        不用多说，让进度比较慢的副本成为leader，肯定是要丢数据的。虽然可能会提高一些可用性，
        但如果你的业务场景丢失数据更加不能忍受，那还是将unclean.leader.election.enable设置为false吧。

- 消费者丢失
    
    消费者丢失的情况，其实跟消费者位移处理不当有关。消费者位移提交有一个参数，enable.auto.commit，默认是true，
    决定是否要让消费者自动提交位移。如果开启，那么consumer每次都是先提交位移，再进行消费，
    比如先跟broker说这5个数据我消费好了，然后才开始慢慢消费这5个数据。
    这样处理的话，好处是简单，坏处就是漏消费数据，比如你说要消费5个数据，
    消费了2个自己就挂了。那下次该consumer重启后，在broker的记录中这个consumer是已经消费了5个的。
    所以最好的做法就是**将enable.auto.commit设置为false**，改为手动提交位移，在每次消费完之后再手动提交位移信息。
    当然这样又有可能会重复消费数据，毕竟exactly once处理一直是一个问题呀（/摊手）。
    遗憾的是kafka目前没有保证consumer幂等消费的措施，如果确实需要保证consumer的幂等，
    可以对每条消息维持一个全局的id，每次消费进行去重，当然耗费这么多的资源来实现exactly once的消费到底值不值，
    那就得看具体业务了。
    
### kafka无消息丢失小结
那么到这里先来总结下无消息丢失的主要配置吧：
- producer的acks设置位-1，同时min.insync.replicas设置大于1。并且使用带有回调的producer api发生消息。
- 默认副本数replication.factor设置为大于1，或者创建topic的时候指定大于1的副本数。
- unclean.leader.election.enable 设置为false，防止定期副本leader重选举消费者端
- 自动提交位移enable.auto.commit设置为false。在消费完后手动提交位移。

那么接下来就来说说kafka实现精确一次（exactly once）处理的方法吧。

### 实现精确一次（exactly once）处理
在分布式环境下，要实现消息一致与精确一次（exactly once）语义处理是很难的。
精确一次处理意味着一个消息只处理一次，造成一次的效果，不能多也不能少。
那么kafka如何能够实现这样的效果呢？
在介绍之前，我们先来介绍其他两个语义，至多一次（at most once）和至少一次（at least once）。

#### 最多一次和至少一次
最多一次就是保证一条消息只发送一次，这个其实最简单，异步发送一次然后不管就可以，缺点是容易丢数据，所以一般不采用。

至少一次语义是kafka默认提供的语义，它保证每条消息都能至少接收并处理一次，缺点是可能有重复数据。

前面有介绍过acks机制，当设置producer客户端的acks是1的时候，broker接收到消息就会跟producer确认。
但producer发送一条消息后，可能因为网络原因消息超时未达，这时候producer客户端会选择重发，
broker回应接收到消息，但很可能最开始发送的消息延迟到达，就会造成消息重复接收。

那么针对这些情况，要如何实现精确一次处理的语义呢？

### 幂等的producer
要介绍幂等的producer之前，得先了解一下幂等这个词是什么意思。
幂等这个词最早起源于函数式编程，意思是一个函数无论执行多少次都会返回一样的结果

kafka提供了让producer支持幂等的配置操作。即：
> props.put("enable.idempotence", ture)

在创建producer客户端的时候，添加这一行配置，producer就变成幂等的了。

注意开启幂等性的时候，acks就自动是“all”了，如果这时候手动将ackss设置为0，那么会报错。

而底层实现其实也很简单，就是对每条消息生成一个id值，broker会根据这个id值进行去重，
从而实现幂等，这样一来就能够实现精确一次的语义了。

但是！幂等的producery也并非万能。有两个主要是缺陷：

- 幂等性的producer仅做到单分区上的幂等性，即单分区消息不重复，多分区无法保证幂等性。
- 只能保持单会话的幂等性，无法实现跨会话的幂等性，也就是说如果producer挂掉再重启，
    无法保证两个会话间的幂等（新会话可能会重发）。因为broker端无法获取之前的状态信息，
    所以无法实现跨会话的幂等。

### 事务的producer
当遇到上述幂等性的缺陷无法解决的时候，可以考虑使用事务了。**事务可以支持多分区的数据完整性，原子性**。
**并且支持跨会话的exactly once处理语义**，也就是说如果producer宕机重启，依旧能保证数据只处理一次。

开启事务也很简单，首先需要开启幂等性，即设置enable.idempotence为true。然后对producer发送代码做一些小小的修改。

```java
producer.initTransactions();
try {
    //开启一个事务
    producer.beginTransaction();
    producer.send(record1);
    producer.send(record2);
    //提交
    producer.commitTransaction();
} catch (KafkaException e) {
    //出现异常的时候，终止事务
    producer.abortTransaction();
}
```
但无论开启幂等还是事务的特性，都会对性能有一定影响，这是必然的。
所以kafka默认也并没有开启这两个特性，而是交由开发者根据自身业务特点进行处理。


### kafka事务消息实现
